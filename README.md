# Анализатор TLI в YDB

Утилита для поиска причин ошибок "Transaction locks invalidated" по серверным логам ydb

Собирает из серверных логов полную картину причин, по которым возникает данная ошибка

## Требования

Нужный функционал логирования доступен в 25.1 свежей версии

## Настройка сервера

По умолчанию ydb не логирует информацию об ошибках TLI и выполняемых запросах.
Чтобы включить сбор этой информации нужно добавить в динамический конфиг следующие настройки:

```yaml
      log_config: !inherit
        entry: !append
          - component: DATA_INTEGRITY
            level: 8
      data_integrity_trails_config: !inherit
        query_text_log_mode: ORIGINAL
```

После применения конфига необходимо перезагрузить узлы базы данных.

Включать секцию `data_integrity_trails_config` не обязательно, по-умолчанию в лог вместо текста запроса будут выводиться его хэш. В целом, если клиентское приложение может логировать запросы самостоятельно, лучше не писать их в лог сервера.

ВАЖНО: после применения этих настроек в лог будет писаться очень подробная информация обо ВСЕХ выполняемых запросах и блокировках. На каждый отправляемый запрос в лог будет записано около 10-15 строк. Настролько подробное логирование отрицательно сказывается на производительности сервера и сильно увеличивает размер логов. Не рекомендуется включать эту настройки в прод-окружении!

## Настройка логирования

По умолчанию ydbd пишет логи в systemd, который отбрасывает часть строк, если приложение пишет слишком много. 
Для целей анализа нам важно собрать все строки, поэтому нужно перенастроить логирование

### Вариант 1: Снять ограничения по объему логов в systemd
Для этого нужно прописать в  /etc/systemd/journald.conf следующие настройки:

```
RateLimitInterval=0
RateLimitBurst=0
```
Затем нужно выполнить `systemctl restart systemd-journald`
При этом ограничение будет снято со всех процессов, запускаемых через systemd

### Вариант 2: Дополнительно сохранять логи в текстовые файлы. 
Для этого нужно дописать в systemd-юниты для динамических нод следующие настройки в раздел [Service]:
```
StandardOutput=append:/var/log/ydbd-database-a.log
StandardError=append:/var/log/ydbd-database-a.log
```
После этого нужно выполнить `systemctl daemon-reload` и перезапустить соответствующий узел ydb

Это нужно сделать в каждом юнит-файле на каждом хосте.
Важно помнить, что каждый процесс должен писать лог в отдельный файл, поэтому имена файлов не должны повторяться на одном хосте.

## Установка и запуск

### Шаг 1: Скачивание проекта

Скачайте проект с GitHub:
```bash
git clone <repository-url>
cd ydb-tli-analyzer
```

Или скачайте архив и распакуйте его в нужную директорию.

### Шаг 2: Установка Python и зависимостей

Убедитесь, что на вашей системе установлен Python 3.8 или выше и библиотека PyYAML:

**Ubuntu/Debian:**
```bash
sudo apt-get install python3 python3-yaml
```

**CentOS/RHEL:**
```bash
sudo yum install python3 python3-pyyaml
```

**macOS:**
```bash
brew install python3
pip3 install pyyaml
```

**Альтернативный способ (через pip):**
```bash
pip3 install pyyaml
```

### Шаг 3: Проверка установки

Проверьте, что Python и PyYAML установлены корректно:
```bash
python3 --version
python3 -c "import yaml; print('PyYAML установлен успешно')"
```

### Шаг 4: Запуск анализатора

Теперь вы можете запустить анализатор напрямую:

## Формат вывода

Инструмент автоматически генерирует три типа отчетов:
 - **report.yaml** - содержит все технические поля в структурированном формате
 - **report.sql** - содержит метаданные и текст запросов в SQL-подобном формате для удобного чтения
 - **summary.txt** - агрегированная сводка с группировкой по комбинациям жертва+виновник

Все три файла создаются одновременно в указанной выходной папке.

## Использование

На вход приложения нужно подать объединенные логи со всех серверов. Для ускорения анализа нужно оставить только строки, содержащие DATA_INTEGRITY.
Желательно дополнительно ограничить период времени, за который анализируются логи.

Сортировать строки не требуется - анализатор сделает это автоматически.

### Примеры использования

**Базовый пример - анализ файла с выводом в отдельную папку:**
```bash
python3 tli_analyzer.py --log-file /path/to/logs/server.log --output-folder ./results
```
Предполагается, что логи со всех серверов уже объединены в один файл

**Анализ с предварительной фильтрацией через grep:**
```bash
grep DATA_INTEGRITY /path/to/logs/*.log | grep "2025-10-22T12:06" | python3 tli_analyzer.py --output-folder ./results
```
Первый grep фильтрует строки с DATA_INTEGRITY
Второй - оставляет только нужный интервал времени

### Параметры командной строки

- `--log-file` - путь к файлу лога (если не указан, читает из stdin)
- `--output-folder` или `-o` - папка для сохранения отчетов (по умолчанию: текущая директория)
- `--log-format` или `-f` - формат входных логов: `raw` (по умолчанию) или `systemd`
- `--no-sort` - отключить автоматическую сортировку логов по времени. Использовать только если логи уже отсортированы (в ОБРАТНОМ порядке!)
- `--collect-details` или `-d` - собирать детальные строки логов для каждой цепочки
- `-v`, `-vv`, `-vvv` - уровни детализации вывода (для отладки)
- `-q` или `--quiet` - минимальный вывод (только ошибки)

